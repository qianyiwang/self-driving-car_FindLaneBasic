{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Finding Lines On the Road\n",
    "- **Environment: python 3.6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas of lane detection pipeline\n",
    " - cv2.inRange() for color selection\n",
    " - cv2.fillPoly() for regions selection\n",
    " - cv2.line() to draw lines on an image\n",
    " - cv2.addWeighted() to coadd/overlay two images\n",
    " - cv2.imwrite() to output images to file\n",
    " - cv2.itwise_and() to apply a mask to an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read image and convert to gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImage(path):\n",
    "    image = cv2.imread(path)\n",
    "    return image\n",
    "\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def drawImage(img):\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color mask\n",
    "```python\n",
    "img[0,0,0] # represents the first pixcel's R chenals value\n",
    "img[:,:,0] # represents all R chenals for all pixcel.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_yellow_filter(img):\n",
    "    white_threshold = [200, 200, 200]\n",
    "    yellow_threshold = [200, 200, 0]\n",
    "    \n",
    "    white_thresholds = (img[:,:,0] < white_threshold[0]) | \\\n",
    "    (img[:,:,1] < white_threshold[1]) | \\\n",
    "    (img[:,:,2] < white_threshold[2])\n",
    "    \n",
    "    yellow_thresholds = (img[:,:,0] > yellow_threshold[0]) | \\\n",
    "    (img[:,:,1] < yellow_threshold[1]) | \\\n",
    "    (img[:,:,2] < yellow_threshold[2])\n",
    "    color_select = np.copy(img)\n",
    "    color_select[white_thresholds & yellow_thresholds] = [0,0,0]\n",
    "    return color_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(img, kernal_size):\n",
    "    return cv2.GaussianBlur(img, (kernal_size, kernal_size), 0)\n",
    "    \n",
    "def findEdge(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find region of interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regionOfInterest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hough lines\n",
    " - lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]),min_line_length, max_line_gap)\n",
    " - rho in units of pixels and theta in units of radians, rho takes a minimum value of 1, and a reasonable starting place for theta is 1 degree (pi/180 in radians).\n",
    " - the threshold parameter specifies the minimum number of votes (intersections in a given grid cell) \n",
    " - the empty np.array([]) is just a placeholder, no need to change it.\n",
    " - min_line_length is the minimum length of a line (in pixels) that you will accept in the output, \n",
    " - max_line_gap is the maximum distance (again, in pixels) between segments that you will allow to be connected into a single line. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    # Returns an image with hough lines drawn.\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), \n",
    "                            minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best line (too complated, won't be used)\n",
    " - First, find the main lines. \n",
    " - Next, find the groups of lines that are similar to eachother (by comparing slope and bias), and save these as \"the same line.\" \n",
    " - Next, take the two most common lines, and assume these must be our lanes. After we've done ROI, the next most likely \"line\" just simply is almost certain to be the lanes. That's the hypothesis anyway!\n",
    "\n",
    "**ms (slop) value is very important for finding lines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ones,vstack\n",
    "from numpy.linalg import lstsq\n",
    "from statistics import mean\n",
    "\n",
    "def findBestLines(shape, lines, leftLineSlop = 1.1, rightLineSlop = 0.93):\n",
    "    try:\n",
    "        ys = []  \n",
    "        for i in lines:\n",
    "            for ii in i:\n",
    "                ys += [ii[1],ii[3]]\n",
    "        min_y = min(ys)\n",
    "        max_y = shape[0]\n",
    "        new_lines = []\n",
    "        line_dict = {}\n",
    "        for idx,i in enumerate(lines):\n",
    "            for xyxy in i:\n",
    "                x_coords = (xyxy[0],xyxy[2])\n",
    "                y_coords = (xyxy[1],xyxy[3])\n",
    "                A = vstack([x_coords,ones(len(x_coords))]).T\n",
    "                m, b = lstsq(A, y_coords)[0]\n",
    "\n",
    "                # Calculating our new, and improved, xs\n",
    "                x1 = (min_y-b) / m\n",
    "                x2 = (max_y-b) / m\n",
    "\n",
    "                line_dict[idx] = [m,b,[int(x1), min_y, int(x2), max_y]]\n",
    "        final_lanes = {}\n",
    "\n",
    "        for idx in line_dict:\n",
    "            final_lanes_copy = final_lanes.copy()\n",
    "            m = line_dict[idx][0]\n",
    "            b = line_dict[idx][1]\n",
    "            line = line_dict[idx][2]\n",
    "            \n",
    "            if len(final_lanes) == 0:\n",
    "                final_lanes[m] = [ [m,b,line] ]\n",
    "                \n",
    "            else:\n",
    "                found_copy = False\n",
    "\n",
    "                for other_ms in final_lanes_copy:\n",
    "\n",
    "                    if not found_copy:\n",
    "                        \n",
    "                        if abs(other_ms*leftLineSlop) > abs(m) > abs(other_ms*rightLineSlop):\n",
    "                            if abs(final_lanes_copy[other_ms][0][1]*leftLineSlop) > abs(b) > abs(final_lanes_copy[other_ms][0][1]*rightLineSlop):\n",
    "                                final_lanes[other_ms].append([m,b,line])\n",
    "                                found_copy = True\n",
    "                                break\n",
    "                        else:\n",
    "                            final_lanes[m] = [ [m,b,line] ]\n",
    "        line_counter = {}\n",
    "\n",
    "        for lanes in final_lanes:\n",
    "            line_counter[lanes] = len(final_lanes[lanes])\n",
    "        top_lanes = sorted(line_counter.items(), key=lambda item: item[1])[::-1][:2]\n",
    "#         print('debug',top_lanes,len(top_lanes))\n",
    "        if(len(top_lanes)==2):\n",
    "            lane1_id = top_lanes[0][0]\n",
    "            lane2_id = top_lanes[1][0]\n",
    "        else:\n",
    "            lane1_id = top_lanes[0][0]\n",
    "            lane2_id = top_lanes[0][0]\n",
    "\n",
    "        def average_lane(lane_data):\n",
    "            x1s = []\n",
    "            y1s = []\n",
    "            x2s = []\n",
    "            y2s = []\n",
    "            for data in lane_data:\n",
    "                x1s.append(data[2][0])\n",
    "                y1s.append(data[2][1])\n",
    "                x2s.append(data[2][2])\n",
    "                y2s.append(data[2][3])\n",
    "            return int(mean(x1s)), int(mean(y1s)), int(mean(x2s)), int(mean(y2s)) \n",
    "\n",
    "        l1_x1, l1_y1, l1_x2, l1_y2 = average_lane(final_lanes[lane1_id])\n",
    "        l2_x1, l2_y1, l2_x2, l2_y2 = average_lane(final_lanes[lane2_id])\n",
    "\n",
    "        return [[l1_x1, l1_y1, l1_x2, l1_y2], [l2_x1, l2_y1, l2_x2, l2_y2]]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best lines v2\n",
    " - check left line or right line\n",
    " - find the longest distance for each side line and record the start and end points\n",
    " - expend the longest lines to roi top and bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lines_v2(lines, vertices):\n",
    "    left_max_dist = -1.0\n",
    "    right_max_dist = -1.0\n",
    "    left_line = []\n",
    "    right_line = []\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            theta1 = y2-y1\n",
    "            theta2 = x2-x1\n",
    "            hyp = math.hypot(theta1,theta2)\n",
    "            m = (y1-y2)/(x2-x1)\n",
    "            if x1<((vertices[0,2,0]-vertices[0,3,0])/2+vertices[0,3,0]) and m>0: # left line\n",
    "                if hyp>left_max_dist:\n",
    "                    left_max_dist = hyp\n",
    "                    left_line = line[0]\n",
    "            if x1>((vertices[0,2,0]-vertices[0,3,0])/2+vertices[0,3,0]) and m<0: # right line\n",
    "                if hyp>right_max_dist:\n",
    "                    right_max_dist = hyp\n",
    "                    right_line = line[0]\n",
    "    def extendLine(line):\n",
    "        try:\n",
    "            x1 = line[0]\n",
    "            y1 = line[1]\n",
    "            x2 = line[2]\n",
    "            y2 = line[3]\n",
    "            m = (y2-y1)/(x2-x1)\n",
    "            b = y1-(y2-y1)*x1/(x2-x1)\n",
    "            y_top = vertices[0,0,1]\n",
    "            y_bottom = vertices[0,2,1]\n",
    "            x_top = (y_top-b)/m\n",
    "            x_bottom = (y_bottom-b)/m\n",
    "            return [int(x_bottom),int(y_bottom),int(x_top),int(y_top)]\n",
    "        except Exception as e:\n",
    "            print('extend line error:',e)\n",
    "            \n",
    "    return [extendLine(left_line), extendLine(right_line)]\n",
    "#     return [left_line, right_line]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw lines on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(shape, lines, color=[255, 0, 0], thickness=5):\n",
    "    line_img = np.zeros((shape[0], shape[1], 3), dtype=np.uint8)\n",
    "    try:\n",
    "        for line in lines:\n",
    "            cv2.line(line_img, (line[0], line[1]), (line[2], line[3]), color, thickness)\n",
    "        return line_img\n",
    "    except Exception as e:\n",
    "        print('draw lines error:',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + γ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return cv2.addWeighted(initial_img, α, img, β, γ)\n",
    "    except Exception as e:\n",
    "        print('weighted_image err:',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveImg(img, path):\n",
    "    try:\n",
    "        cv2.imwrite(path, img)\n",
    "    except Exception as e:\n",
    "        print('same image error',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test images\n",
    " - Build your pipeline that will draw lane lines on the test_images\n",
    " - Save them to the test_images_output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 3/6 [00:00<00:00, 22.54it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "[[161, 540, 409, 360], [858, 540, 561, 360]]\n",
      "========\n",
      "[[156, 540, 404, 360], [859, 540, 569, 360]]\n",
      "========\n",
      "[[160, 540, 407, 360], [853, 540, 561, 360]]\n",
      "========\n",
      "[[118, 540, 412, 360], [853, 540, 566, 360]]\n",
      "========\n",
      "[[191, 540, 420, 360], [887, 540, 562, 360]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 22.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "[[195, 540, 416, 360], [881, 540, 570, 360]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm \n",
    "\n",
    "DIR = 'test_images'\n",
    "for name in tqdm(os.listdir(DIR)):\n",
    "    path = os.path.join(DIR, name)\n",
    "    image = readImage(path)\n",
    "    # imply color masker\n",
    "    color_select = white_yellow_filter(image)\n",
    "    # find edge\n",
    "    gray = grayscale(color_select)\n",
    "    edge = findEdge(gaussian_blur(gray,3), 150, 300)\n",
    "    # create vertices and roi image\n",
    "    left_bottom = (0, image.shape[0])\n",
    "    right_bottom = (image.shape[1], image.shape[0])\n",
    "    left_top = (image.shape[1]/3, image.shape[0]*2/3)\n",
    "    right_top = (image.shape[1]*2/3, image.shape[0]*2/3)\n",
    "    vertices = np.array([[left_top, right_top, right_bottom, left_bottom]], dtype=np.int32)\n",
    "    maskedImage = regionOfInterest(edge, vertices)\n",
    "    \n",
    "    # create hough lines\n",
    "    rho = 1\n",
    "    theta = np.pi/180\n",
    "    threshold = 1\n",
    "    min_line_length = 20\n",
    "    max_line_gap = 15\n",
    "    lines = hough_lines(maskedImage, rho, theta, \n",
    "                        threshold, min_line_length, max_line_gap)\n",
    "    print('========')\n",
    "    bestLines = find_lines_v2(lines,vertices)#findBestLines(image.shape, lines)\n",
    "    print(bestLines)\n",
    "    \n",
    "    line_img = draw_lines(image.shape, bestLines)\n",
    "    # draw on image\n",
    "    result = weighted_img(line_img, image)\n",
    "    saveImg(result, f'test_image_output/{name}')\n",
    "#     plt.imshow(result)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on videos\n",
    " - To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    " - To do so add .subclip(start_second,end_second) to the end of the line below\n",
    " - Where start_second and end_second are integer values representing the start and end of the subclip\n",
    " - You may also uncomment the following line for a subclip of the first 5 seconds\n",
    " - clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    gray = grayscale(image)\n",
    "    edge = findEdge(gaussian_blur(gray,3), 150, 300)\n",
    "    # create vertices and roi image\n",
    "    left_bottom = (0, image.shape[0])\n",
    "    right_bottom = (image.shape[1], image.shape[0])\n",
    "    left_top = (image.shape[1]/3, image.shape[0]*2/3)\n",
    "    right_top = (image.shape[1]*2/3, image.shape[0]*2/3)\n",
    "    vertices = np.array([[left_top, right_top, right_bottom, left_bottom]], dtype=np.int32)\n",
    "    maskedImage = regionOfInterest(edge, vertices)\n",
    "    \n",
    "    # create hough lines\n",
    "    rho = 1\n",
    "    theta = np.pi/180\n",
    "    threshold = 1\n",
    "    min_line_length = 20\n",
    "    max_line_gap = 15\n",
    "    lines = hough_lines(maskedImage, rho, theta, \n",
    "                        threshold, min_line_length, max_line_gap)\n",
    "\n",
    "    bestLines = find_lines_v2(lines,vertices)#findBestLines(image.shape, lines, 1.1, 0.93)\n",
    "    line_img = draw_lines(image.shape, bestLines)\n",
    "    # draw on image\n",
    "    if line_img is None:\n",
    "        return image\n",
    "    result = weighted_img(line_img, image)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 13/222 [00:00<00:01, 126.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 28/222 [00:00<00:01, 131.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 42/222 [00:00<00:01, 131.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 51/222 [00:00<00:01, 101.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 61/222 [00:00<00:01, 99.67it/s] \u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 71/222 [00:00<00:01, 98.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 81/222 [00:00<00:01, 96.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 91/222 [00:00<00:01, 96.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 102/222 [00:00<00:01, 98.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 112/222 [00:01<00:01, 98.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 124/222 [00:01<00:00, 102.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 135/222 [00:01<00:00, 97.72it/s] \u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 145/222 [00:01<00:00, 97.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 155/222 [00:01<00:00, 98.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 165/222 [00:01<00:00, 97.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 175/222 [00:01<00:00, 96.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 185/222 [00:01<00:00, 94.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 195/222 [00:01<00:00, 94.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 205/222 [00:02<00:00, 95.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 215/222 [00:02<00:00, 95.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 221/222 [00:02<00:00, 99.98it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "CPU times: user 1.74 s, sys: 316 ms, total: 2.06 s\n",
      "Wall time: 2.53 s\n",
      "[MoviePy] >>>> Building video test_videos_output/challenge.mp4\n",
      "[MoviePy] Writing video test_videos_output/challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/251 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 9/251 [00:00<00:02, 87.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 18/251 [00:00<00:02, 87.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 27/251 [00:00<00:02, 87.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 36/251 [00:00<00:02, 87.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 46/251 [00:00<00:02, 88.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 54/251 [00:00<00:03, 61.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 61/251 [00:00<00:03, 59.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 68/251 [00:01<00:03, 56.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 74/251 [00:01<00:03, 56.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/251 [00:01<00:03, 54.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 86/251 [00:01<00:03, 53.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 93/251 [00:01<00:02, 55.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 99/251 [00:01<00:02, 54.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 105/251 [00:01<00:02, 53.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 111/251 [00:01<00:02, 53.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 117/251 [00:01<00:02, 53.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 123/251 [00:02<00:02, 55.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 129/251 [00:02<00:02, 49.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 135/251 [00:02<00:02, 46.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 140/251 [00:02<00:02, 47.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 145/251 [00:02<00:02, 47.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 150/251 [00:02<00:02, 45.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 155/251 [00:02<00:02, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 160/251 [00:02<00:02, 44.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 166/251 [00:02<00:01, 47.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 171/251 [00:03<00:01, 42.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 178/251 [00:03<00:01, 46.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 183/251 [00:03<00:01, 38.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 189/251 [00:03<00:01, 42.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 194/251 [00:03<00:01, 38.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 200/251 [00:03<00:01, 40.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 205/251 [00:03<00:01, 39.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 211/251 [00:04<00:00, 42.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 216/251 [00:04<00:00, 44.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 221/251 [00:04<00:00, 43.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 228/251 [00:04<00:00, 47.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 233/251 [00:04<00:00, 45.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 239/251 [00:04<00:00, 47.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 244/251 [00:04<00:00, 47.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 251/251 [00:04<00:00, 51.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/challenge.mp4 \n",
      "\n",
      "CPU times: user 3.43 s, sys: 490 ms, total: 3.92 s\n",
      "Wall time: 5.53 s\n",
      "[MoviePy] >>>> Building video test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 13/682 [00:00<00:05, 122.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 28/682 [00:00<00:05, 128.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 43/682 [00:00<00:04, 133.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 53/682 [00:00<00:05, 110.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 64/682 [00:00<00:05, 109.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 74/682 [00:00<00:05, 105.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 84/682 [00:00<00:05, 102.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 94/682 [00:00<00:05, 98.67it/s] \u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 104/682 [00:00<00:05, 98.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 114/682 [00:01<00:05, 96.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 125/682 [00:01<00:05, 97.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 135/682 [00:01<00:05, 96.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 146/682 [00:01<00:05, 98.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 156/682 [00:01<00:05, 96.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 166/682 [00:01<00:05, 97.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 176/682 [00:01<00:05, 95.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 187/682 [00:01<00:05, 96.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 197/682 [00:01<00:05, 94.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 207/682 [00:02<00:04, 96.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 217/682 [00:02<00:04, 96.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 227/682 [00:02<00:04, 95.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 237/682 [00:02<00:04, 96.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 247/682 [00:02<00:04, 91.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 257/682 [00:02<00:04, 93.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 267/682 [00:02<00:04, 95.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 278/682 [00:02<00:04, 97.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 288/682 [00:02<00:04, 98.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 298/682 [00:02<00:04, 91.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 309/682 [00:03<00:03, 95.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 319/682 [00:03<00:03, 95.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 329/682 [00:03<00:03, 96.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 339/682 [00:03<00:03, 96.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 349/682 [00:03<00:03, 95.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 360/682 [00:03<00:03, 97.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 370/682 [00:03<00:03, 94.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 380/682 [00:03<00:03, 94.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 390/682 [00:03<00:03, 95.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 401/682 [00:04<00:02, 96.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 411/682 [00:04<00:02, 97.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 421/682 [00:04<00:02, 96.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 431/682 [00:04<00:02, 95.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 441/682 [00:04<00:02, 95.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 452/682 [00:04<00:02, 96.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 462/682 [00:04<00:02, 96.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 472/682 [00:04<00:02, 94.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 482/682 [00:04<00:02, 93.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 492/682 [00:05<00:02, 91.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 502/682 [00:05<00:01, 93.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 512/682 [00:05<00:01, 91.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 522/682 [00:05<00:01, 91.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 532/682 [00:05<00:01, 92.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 542/682 [00:05<00:01, 90.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 552/682 [00:05<00:01, 91.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 562/682 [00:05<00:01, 90.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 573/682 [00:05<00:01, 93.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 583/682 [00:06<00:01, 87.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 592/682 [00:06<00:01, 87.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 602/682 [00:06<00:00, 88.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 612/682 [00:06<00:00, 90.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 622/682 [00:06<00:00, 89.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 633/682 [00:06<00:00, 92.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 643/682 [00:06<00:00, 91.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 653/682 [00:06<00:00, 92.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 663/682 [00:06<00:00, 90.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 673/682 [00:07<00:00, 92.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 681/682 [00:07<00:00, 95.99it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidYellowLeft.mp4 \n",
      "\n",
      "CPU times: user 5.33 s, sys: 933 ms, total: 6.26 s\n",
      "Wall time: 7.46 s\n"
     ]
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "DIR = 'test_videos'\n",
    "white_output = 'test_videos_output'\n",
    "for name in os.listdir(DIR):\n",
    "    path = os.path.join(DIR, name)\n",
    "    outPath = os.path.join(white_output, name)\n",
    "\n",
    "    clip1 = VideoFileClip(path)\n",
    "    white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "    try:\n",
    "        %time white_clip.write_videofile(outPath, audio=False)   \n",
    "        HTML(\"\"\"\n",
    "        <video width=\"960\" height=\"540\" controls>\n",
    "          <source src=\"{0}\">\n",
    "        </video>\n",
    "        \"\"\".format(outPath))\n",
    "    except Exception as e:\n",
    "        print('clip write error:',e)\n",
    "\n",
    "# path = 'test_videos/challenge.mp4'\n",
    "# outPath = 'test_videos_output/challenge.mp4'\n",
    "\n",
    "# clip1 = VideoFileClip(path)\n",
    "# white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "# white_clip.write_videofile(outPath, audio=False)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
